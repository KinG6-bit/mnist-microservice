# -*- coding: utf-8 -*-
"""main.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HvbKeE9Iz5n4Bzw8_OoJpbIhSrnN4awp
"""

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import torch
import torch.nn.functional as F
import numpy as np

app = FastAPI()

# Load the TorchScript model
model = torch.jit.load("softmax_regression_scripted.pt")
model.eval()

# Define input format
class InputData(BaseModel):
    input: list  # 3D list: [1, 28, 28]

@app.post("/predict")
async def predict(data: InputData):
    try:
        # Convert input to tensor
        arr = np.array(data.input, dtype=np.float32)
        if arr.shape != (1, 28, 28):
            raise ValueError("Input must be of shape [1, 28, 28]")

        tensor = torch.tensor(arr).unsqueeze(0)  # [1, 1, 28, 28]

        with torch.no_grad():
            output = model(tensor)
            scores = output.squeeze().tolist()
            pred_class = int(torch.argmax(output))

        return {
            "predicted_class": pred_class,
            "scores": scores
        }
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@app.get("/")
def read_root():
    return {"message": "MNIST classifier is up! Use POST /predict."}

